{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Available: False\n",
      "MPS Available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"NVIDIA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_0d = torch.tensor(1)\n",
    "tensor_1d = torch.tensor([1,2,3])\n",
    "tensor_2d = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor_3d = torch.tensor([[[1,2,3],[4,5,6]],[[1,2,3],[4,5,6]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type (dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of 3d tensor: torch.Size([2, 2, 3])\n",
      "type of 3d tensor: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of 3d tensor: {tensor_3d.shape}\")\n",
    "print(f\"type of 3d tensor: {tensor_3d.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# change the type of a tensor\n",
    "tensor_0d = tensor_0d.to(torch.float32)\n",
    "print(tensor_0d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_2d)\n",
    "print(tensor_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the matrix\n",
    "tensor_2d.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the matrix\n",
    "tensor_2d.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose the matrix\n",
    "tensor_2d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2d.matmul(tensor_2d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2d @ tensor_2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([1.0]) # true label\n",
    "x1 = torch.tensor([1.1]) # input feature\n",
    "w1 = torch.tensor([2.2]) # weight parameter\n",
    "b = torch.tensor([0.0]) # bias unit\n",
    "\n",
    "z = x1 * w1 + b # net input\n",
    "a = torch.sigmoid(z) # output\n",
    "\n",
    "loss = F.binary_cross_entropy(a,y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.requires_grad , b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([1.0]) # true label\n",
    "x1 = torch.tensor([1.1]) # input feature\n",
    "w1 = torch.tensor([2.2], requires_grad=True) # weight parameter\n",
    "b = torch.tensor([0.0], requires_grad=True) # bias unit\n",
    "\n",
    "z = x1 * w1 + b # net input\n",
    "a = torch.sigmoid(z) # output\n",
    "\n",
    "loss = F.binary_cross_entropy(a,y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import grad\n",
    "\n",
    "grad_loss_w1 = grad(loss,w1,retain_graph=True) # PyTorch destroys the computation graph after calculating the gradients to free memory. However, since we are going to reuse this computation graph shortly, we set retain_graph=True so that it stays in memory.\n",
    "grad_loss_b = grad(loss,b,retain_graph=True)\n",
    "\n",
    "print(grad_loss_w1)\n",
    "print(grad_loss_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "#automate the above process\n",
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # 1st hl\n",
    "            torch.nn.Linear(in_dim, 30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            #2nd hl\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output l\n",
    "            torch.nn.Linear(20, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.manual_seed(123)\n",
    "model = NeuralNetwork(50,3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2213\n"
     ]
    }
   ],
   "source": [
    "# calculate number of params\n",
    "number_params = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        number_params+=p.numel()\n",
    "print(number_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0577, -0.0875,  0.0094, -0.1068,  0.1104,  0.0912, -0.1130,  0.0303,\n",
      "         0.1071, -0.0189, -0.1048,  0.0422, -0.0065, -0.0019, -0.0817,  0.0769,\n",
      "        -0.0420,  0.0252, -0.0319, -0.0123,  0.0887, -0.0871,  0.1399, -0.0468,\n",
      "        -0.0180,  0.0284, -0.0508, -0.0411, -0.0350, -0.0682],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1133,  0.1053,  0.0403,  ...,  0.1004, -0.1149,  0.0923],\n",
      "        [-0.0896, -0.0357,  0.0218,  ...,  0.0985,  0.0785, -0.0420],\n",
      "        [-0.1369,  0.0134, -0.0823,  ..., -0.0825, -0.0592, -0.0243],\n",
      "        ...,\n",
      "        [-0.0608, -0.0583,  0.1045,  ..., -0.0257, -0.0957, -0.1372],\n",
      "        [ 0.1338,  0.0606, -0.0176,  ..., -0.1136, -0.0317, -0.0992],\n",
      "        [-0.0429,  0.1365,  0.0176,  ..., -0.0850,  0.0983, -0.1007]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].bias)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0131, -0.1209, -0.0638]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "X = torch.rand((1,50))\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3511, 0.3152, 0.3337]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = torch.softmax(model(X),dim=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random train/test dataset\n",
    "X_train = torch.tensor(\n",
    "    [\n",
    "        [-1.2, 3.1],\n",
    "        [-0.9, 2.9],\n",
    "        [-0.5, 2.6],\n",
    "        [2.3, -1.1],\n",
    "        [2.7, -1.5]\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_train = torch.tensor(\n",
    "    [0,0,0,1,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(\n",
    "    [\n",
    "        [-0.8, 2.8],\n",
    "        [2.6, -1.6],\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_test = torch.tensor(\n",
    "    [0,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# the main compenents of a costum Dataset class are the __init__ , __getitem__ and __len__\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x,one_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ToyDataset(X_train,y_train)\n",
    "test_dataset = ToyDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.7000, -1.5000]), tensor(1))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) # get len\n",
    "train_dataset[-1] # get idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "DataLoader(\n",
      "    dataset: torch.utils.data.dataset.Dataset[+_T_co],\n",
      "    batch_size: Optional[int] = \u001b[32m1\u001b[39m,\n",
      "    shuffle: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    sampler: Union[torch.utils.data.sampler.Sampler, collections.abc.Iterable, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    batch_sampler: Union[torch.utils.data.sampler.Sampler[list], collections.abc.Iterable[list], NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    num_workers: int = \u001b[32m0\u001b[39m,\n",
      "    collate_fn: Optional[Callable[[list[~_T]], Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pin_memory: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    drop_last: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    timeout: float = \u001b[32m0\u001b[39m,\n",
      "    worker_init_fn: Optional[Callable[[int], NoneType]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    multiprocessing_context=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    generator=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    prefetch_factor: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    persistent_workers: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    pin_memory_device: str = \u001b[33m''\u001b[39m,\n",
      "    in_order: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` on if ``pin_memory`` is\n",
      "        ``True``. If not given, the current :ref:`accelerator<accelerators>` will be the\n",
      "        default. This argument is discouraged and subject to deprecated.\n",
      "    in_order (bool, optional): If ``False``, the data loader will not enforce that batches\n",
      "        are returned in a first-in, first-out order. Only applies when ``num_workers > 0``. (default: ``True``)\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. warning:: Setting `in_order` to `False` can harm reproducibility and may lead to a skewed data\n",
      "             distribution being fed to the trainer in cases with imbalanced data.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[31mFile:\u001b[39m           ~/Desktop/projects/study_projects/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(\n",
    "    dataset= train_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    "    num_workers= 0 # If multiple workers are enabled, the data loader can already queue up the next batch in the background\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader= DataLoader(\n",
    "    dataset= test_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    num_workers= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: (tensor([[-1.2000,  3.1000],\n",
      "        [-0.9000,  2.9000]]), tensor([0, 0]))\n",
      "Batch 2: (tensor([[ 2.3000, -1.1000],\n",
      "        [ 2.7000, -1.5000]]), tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "for i, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {i+1}: {x,y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch1: (tensor([[-1.2000,  3.1000],\n",
      "        [-0.9000,  2.9000]]), tensor([0, 0]))\n",
      "Batch2: (tensor([[ 2.3000, -1.1000],\n",
      "        [ 2.7000, -1.5000]]), tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "# drop the last batch \n",
    "train_loader= DataLoader(\n",
    "    dataset= train_dataset,\n",
    "    batch_size= 2,\n",
    "    shuffle= True,\n",
    "    num_workers= 0,\n",
    "    drop_last= True\n",
    ")\n",
    "for i,(x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch{i+1}: {x,y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical Trianing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 1/3 | Batch 0/2 | Train Loss 0.46 \n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 1/3 | Batch 1/2 | Train Loss 1.14 \n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 2/3 | Batch 0/2 | Train Loss 0.23 \n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 2/3 | Batch 1/2 | Train Loss 0.07 \n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 3/3 | Batch 0/2 | Train Loss 0.07 \n",
      "torch.Size([2, 2]) torch.Size([2])\n",
      "Epoch 3/3 | Batch 1/2 | Train Loss 0.02 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model = NeuralNetwork(2,2)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.5)\n",
    "num_epochs= 3\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    model.train() # if we have dropout or normalization in our arch (activate)\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        logits= model(x)\n",
    "        print(logits.shape,y.shape)\n",
    "        loss = F.cross_entropy(logits,y)\n",
    "\n",
    "        optimizer.zero_grad() #reset gradient to zero otherwise the gradient will accumulate\n",
    "        loss.backward() # calculate the gradient\n",
    "        optimizer.step() # update parameters\n",
    "\n",
    "        print(f\"Epoch {e+1}/{num_epochs} | Batch {i}/{len(train_loader)} | Train Loss {loss:.2f} \")\n",
    "    model.eval() # deactivate dropout and batch normalization\n",
    "    # Optional model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9784, 0.0216],\n",
       "        [0.0048, 0.9952]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "torch.softmax(outputs,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False) # used here to make the outputs more legible.\n",
    "y_predict = torch.argmax(torch.softmax(outputs,dim=1),dim=1)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y_predict == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model,dataloader):\n",
    "    correct_labels = 0.0\n",
    "    total_labels = 0\n",
    "\n",
    "    for (x,y) in dataloader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits= model(x)\n",
    "        predicted_labels= torch.argmax(logits,dim=1)\n",
    "        predicted_labels= predicted_labels==y \n",
    "        correct_labels+= torch.sum(predicted_labels)\n",
    "        total_labels+= len(predicted_labels)\n",
    "    return (correct_labels/total_labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers.0.weight',\n",
       "              tensor([[ 0.7017, -0.1831],\n",
       "                      [-0.2414,  0.1945],\n",
       "                      [ 0.2748, -0.3816],\n",
       "                      [ 0.3879,  0.1403],\n",
       "                      [ 0.5233, -0.3944],\n",
       "                      [ 0.6558, -0.2588],\n",
       "                      [ 0.6765,  0.4306],\n",
       "                      [ 0.4291, -0.1179],\n",
       "                      [-0.1032, -0.4993],\n",
       "                      [-0.1749,  0.3715],\n",
       "                      [-0.2227, -0.4528],\n",
       "                      [ 0.3145,  0.3721],\n",
       "                      [-0.4028,  0.3713],\n",
       "                      [ 0.4374,  0.1186],\n",
       "                      [-0.5328, -0.3546],\n",
       "                      [-0.3286, -0.3685],\n",
       "                      [-0.3631, -0.0938],\n",
       "                      [-0.1297, -0.3198],\n",
       "                      [ 0.6690,  0.0767],\n",
       "                      [ 0.6646, -0.1820],\n",
       "                      [-0.5471, -0.6472],\n",
       "                      [ 0.3296, -0.4531],\n",
       "                      [ 0.2784, -0.6826],\n",
       "                      [ 0.6107,  0.1265],\n",
       "                      [-0.6233,  0.7306],\n",
       "                      [-0.1305, -0.4952],\n",
       "                      [ 0.5192,  0.4820],\n",
       "                      [-0.0664, -0.2717],\n",
       "                      [-0.2676, -0.0506],\n",
       "                      [ 0.6037, -0.4575]])),\n",
       "             ('layers.0.bias',\n",
       "              tensor([-0.5212, -0.4438, -0.3543,  0.2591, -0.3986, -0.6442, -0.5543,  0.4383,\n",
       "                      -0.2558, -0.1684, -0.3177, -0.3833,  0.5206,  0.3057,  0.1026,  0.0079,\n",
       "                      -0.1064,  0.3653, -0.0354, -0.5145,  0.1116,  0.0615, -0.4235, -0.1136,\n",
       "                       0.4958, -0.2190,  0.0132,  0.6454, -0.5264, -0.6526])),\n",
       "             ('layers.2.weight',\n",
       "              tensor([[     0.0911,     -0.1178,     -0.0324,     -0.0281,     -0.0721,\n",
       "                            0.0330,     -0.0635,     -0.0874,      0.1042,     -0.0776,\n",
       "                           -0.1633,     -0.0222,     -0.0759,     -0.1059,      0.0411,\n",
       "                            0.0598,     -0.0382,      0.0791,     -0.0697,      0.1796,\n",
       "                           -0.1172,     -0.0070,     -0.0972,      0.1389,     -0.0275,\n",
       "                            0.1345,      0.1125,      0.0456,      0.0874,     -0.1713],\n",
       "                      [     0.3307,     -0.0796,      0.0661,      0.0922,      0.3178,\n",
       "                            0.1897,      0.1276,      0.2502,      0.0332,     -0.1977,\n",
       "                           -0.0122,     -0.0522,     -0.2662,      0.1670,      0.1723,\n",
       "                            0.0327,     -0.0970,      0.0962,      0.2911,      0.2014,\n",
       "                            0.0452,      0.2165,      0.2224,      0.0840,     -0.2765,\n",
       "                           -0.1043,     -0.0727,      0.1666,     -0.0721,      0.0544],\n",
       "                      [     0.0774,      0.0944,     -0.1735,      0.0189,     -0.1066,\n",
       "                            0.0538,      0.0598,     -0.0710,     -0.0905,      0.1595,\n",
       "                           -0.0208,      0.1603,     -0.0773,      0.0911,     -0.0808,\n",
       "                           -0.0246,     -0.1822,      0.1611,      0.1241,     -0.1292,\n",
       "                           -0.1302,     -0.0644,      0.1509,      0.0455,      0.0374,\n",
       "                           -0.1567,     -0.1586,     -0.1075,     -0.1395,     -0.0416],\n",
       "                      [    -0.1439,     -0.0887,     -0.0412,     -0.0985,     -0.1565,\n",
       "                            0.0535,      0.1531,     -0.1773,      0.1808,     -0.0809,\n",
       "                            0.1202,      0.0745,      0.1336,     -0.1167,     -0.0064,\n",
       "                           -0.1201,      0.0013,      0.0646,      0.1123,     -0.1100,\n",
       "                           -0.1063,     -0.0681,     -0.0302,     -0.0413,     -0.2073,\n",
       "                            0.1673,      0.0269,     -0.0272,     -0.0775,      0.0682],\n",
       "                      [     0.1646,      0.1285,     -0.1816,     -0.0343,     -0.1846,\n",
       "                           -0.0592,     -0.0035,     -0.1286,     -0.1356,      0.1619,\n",
       "                            0.1600,      0.0217,      0.3642,     -0.0152,     -0.0209,\n",
       "                           -0.1771,     -0.0439,     -0.1694,      0.0320,      0.1347,\n",
       "                           -0.0891,     -0.0114,     -0.0286,      0.1051,      0.5152,\n",
       "                           -0.1707,      0.0757,     -0.0233,      0.0306,     -0.0365],\n",
       "                      [    -0.1276,      0.1137,     -0.0060,     -0.1313,     -0.1516,\n",
       "                           -0.1444,     -0.1766,     -0.0941,     -0.1110,     -0.0919,\n",
       "                           -0.0043,      0.0327,      0.0666,     -0.1159,      0.0112,\n",
       "                            0.0315,     -0.1046,      0.0611,     -0.1593,     -0.1751,\n",
       "                            0.0211,     -0.1320,      0.0933,     -0.0396,      0.0666,\n",
       "                           -0.0820,     -0.1222,      0.0616,      0.0327,      0.0670],\n",
       "                      [     0.0344,     -0.0493,      0.0976,      0.0938,     -0.0940,\n",
       "                            0.0239,      0.0467,     -0.1350,     -0.0469,     -0.1775,\n",
       "                           -0.0782,     -0.0377,     -0.0890,      0.0319,      0.1488,\n",
       "                           -0.0237,     -0.1697,      0.1273,     -0.0397,      0.1173,\n",
       "                           -0.0522,     -0.1513,     -0.0567,      0.0143,      0.0831,\n",
       "                            0.1575,      0.0378,      0.0561,     -0.0709,     -0.0283],\n",
       "                      [     0.0561,      0.0119,      0.1359,      0.0615,      0.0292,\n",
       "                            0.1614,     -0.1627,      0.1101,      0.0932,     -0.1361,\n",
       "                            0.1155,     -0.0098,     -0.0660,     -0.0977,     -0.0237,\n",
       "                           -0.1683,      0.1098,     -0.1771,      0.0979,      0.1665,\n",
       "                            0.1637,      0.1735,     -0.0462,     -0.1569,     -0.0980,\n",
       "                            0.0498,     -0.0145,     -0.1183,      0.1454,      0.1284],\n",
       "                      [    -0.0479,     -0.0429,     -0.0173,      0.0882,     -0.1004,\n",
       "                           -0.1524,     -0.0323,     -0.0861,     -0.1544,     -0.0621,\n",
       "                            0.0028,      0.0148,      0.0213,     -0.0391,      0.0328,\n",
       "                            0.1557,     -0.0960,      0.1176,     -0.1211,     -0.0400,\n",
       "                            0.1654,     -0.0700,     -0.1344,     -0.0879,      0.3120,\n",
       "                           -0.1626,      0.0116,     -0.1031,      0.0118,      0.0954],\n",
       "                      [     0.1807,      0.1030,     -0.1003,     -0.0520,      0.1446,\n",
       "                           -0.1678,      0.0873,     -0.1749,     -0.0607,      0.0101,\n",
       "                           -0.0146,      0.0612,      0.0525,     -0.0836,      0.0295,\n",
       "                            0.1129,     -0.1209,      0.0846,     -0.1242,     -0.0192,\n",
       "                            0.1343,      0.1289,      0.0552,     -0.0188,     -0.1603,\n",
       "                            0.1623,     -0.0965,      0.1185,      0.1168,      0.1142],\n",
       "                      [    -0.0776,     -0.0400,      0.0335,     -0.1131,     -0.0556,\n",
       "                           -0.0541,      0.1312,     -0.1358,      0.0375,      0.1487,\n",
       "                            0.0554,     -0.0022,      0.0273,     -0.0391,     -0.1242,\n",
       "                            0.0245,     -0.1688,     -0.0854,     -0.0866,      0.0059,\n",
       "                            0.0144,      0.1791,      0.0672,     -0.0060,      0.0309,\n",
       "                           -0.1174,     -0.0031,      0.1198,      0.1492,     -0.0686],\n",
       "                      [    -0.1169,      0.1497,      0.0581,      0.0168,     -0.0275,\n",
       "                            0.0146,      0.0962,      0.0544,     -0.0367,      0.0275,\n",
       "                           -0.1161,      0.0085,      0.1711,     -0.1347,     -0.1128,\n",
       "                            0.0976,     -0.1772,      0.1323,     -0.1418,      0.1570,\n",
       "                           -0.0004,      0.1152,     -0.1496,     -0.1675,     -0.1249,\n",
       "                           -0.1692,     -0.0027,     -0.1266,     -0.1150,      0.0492],\n",
       "                      [    -0.1781,      0.0744,      0.1230,     -0.0355,      0.1768,\n",
       "                           -0.0034,     -0.0994,      0.0914,     -0.0488,      0.1308,\n",
       "                           -0.1796,     -0.0235,      0.0342,     -0.0636,      0.0514,\n",
       "                            0.0874,      0.1108,      0.0195,     -0.0376,      0.0554,\n",
       "                           -0.1432,      0.1811,      0.0100,      0.0015,     -0.2581,\n",
       "                            0.1682,     -0.1401,      0.0750,     -0.1517,     -0.1806],\n",
       "                      [     0.0074,      0.1328,     -0.0252,     -0.2033,     -0.2704,\n",
       "                            0.0395,     -0.0644,      0.0218,      0.1003,      0.0805,\n",
       "                           -0.1372,      0.0710,     -0.0020,     -0.0065,     -0.0137,\n",
       "                           -0.0425,      0.0190,     -0.0009,     -0.2332,     -0.1304,\n",
       "                            0.1314,     -0.2810,      0.0819,     -0.0549,      0.1545,\n",
       "                           -0.1756,     -0.0052,      0.0152,     -0.1204,     -0.2729],\n",
       "                      [    -0.0457,     -0.0612,      0.1047,      0.0159,     -0.0886,\n",
       "                            0.2440,      0.1848,      0.1704,      0.0464,     -0.0281,\n",
       "                            0.1744,      0.0632,      0.1024,      0.1455,      0.1701,\n",
       "                            0.1650,     -0.1769,      0.0807,      0.0033,      0.0593,\n",
       "                            0.1168,     -0.0225,     -0.0081,      0.0544,     -0.1709,\n",
       "                            0.1292,      0.0075,      0.1367,      0.0507,      0.2087],\n",
       "                      [    -0.2795,     -0.0889,     -0.0465,     -0.0102,     -0.0878,\n",
       "                           -0.2647,      0.0215,     -0.1317,      0.0655,      0.1522,\n",
       "                            0.1723,      0.0884,      0.0520,      0.0251,     -0.0854,\n",
       "                            0.0048,     -0.1428,     -0.1282,     -0.0692,     -0.1677,\n",
       "                            0.1154,     -0.1418,     -0.2718,     -0.1156,      0.3163,\n",
       "                           -0.0511,     -0.0804,     -0.2020,      0.1446,     -0.2673],\n",
       "                      [     0.0235,      0.1540,      0.0255,     -0.1548,     -0.0127,\n",
       "                           -0.1657,     -0.0068,      0.1678,      0.0093,      0.1097,\n",
       "                           -0.1686,      0.1063,      0.0497,      0.0713,     -0.0667,\n",
       "                           -0.1502,     -0.0613,     -0.0006,     -0.1706,     -0.1095,\n",
       "                           -0.1565,      0.1722,      0.0949,     -0.0574,      0.0362,\n",
       "                           -0.1807,     -0.0130,      0.0278,     -0.1225,     -0.0432],\n",
       "                      [    -0.0216,      0.1151,     -0.0136,      0.0696,      0.0691,\n",
       "                           -0.0370,     -0.0301,      0.0653,      0.0063,     -0.1580,\n",
       "                            0.1299,     -0.0821,      0.0060,     -0.0953,     -0.1701,\n",
       "                            0.0841,      0.1099,     -0.0463,     -0.2071,     -0.1680,\n",
       "                           -0.0175,      0.1295,     -0.1843,     -0.0158,     -0.0043,\n",
       "                           -0.0046,     -0.0305,      0.0478,      0.1338,      0.0996],\n",
       "                      [    -0.1686,      0.0796,      0.1442,     -0.1487,     -0.1388,\n",
       "                           -0.1497,      0.1585,     -0.1222,      0.0489,     -0.1816,\n",
       "                            0.0176,     -0.0349,     -0.0780,     -0.0047,      0.0338,\n",
       "                           -0.0691,     -0.1682,      0.1310,     -0.0053,     -0.0130,\n",
       "                            0.0164,     -0.0697,     -0.0075,     -0.1735,     -0.1622,\n",
       "                            0.0453,      0.0794,     -0.0351,      0.0084,      0.0815],\n",
       "                      [    -0.1418,      0.1763,     -0.1495,      0.0033,     -0.0240,\n",
       "                           -0.1204,     -0.0080,     -0.0423,     -0.1780,      0.1174,\n",
       "                           -0.1128,      0.1331,      0.0112,     -0.0050,     -0.0957,\n",
       "                            0.0330,     -0.0412,     -0.1012,     -0.0144,     -0.0881,\n",
       "                           -0.0041,      0.0428,      0.1517,      0.1701,      0.1713,\n",
       "                           -0.1428,     -0.1017,      0.0512,     -0.0622,      0.0793]])),\n",
       "             ('layers.2.bias',\n",
       "              tensor([-0.0669,  0.1811, -0.1482,  0.1331,  0.1492, -0.1680, -0.1758, -0.0151,\n",
       "                      -0.0136,  0.0378, -0.0191, -0.0679, -0.1717, -0.0855, -0.0503,  0.0915,\n",
       "                       0.0578, -0.0756, -0.0166,  0.0129])),\n",
       "             ('layers.4.weight',\n",
       "              tensor([[ 0.0799, -0.5449, -0.1304, -0.0293,  0.4937, -0.1144,  0.0844, -0.2415,\n",
       "                        0.0798,  0.0596,  0.0778,  0.1348, -0.1925,  0.1724, -0.0765,  0.0843,\n",
       "                        0.0210, -0.2510,  0.1546, -0.0152],\n",
       "                      [-0.0313,  0.5514,  0.0888,  0.0815, -0.4282, -0.0034,  0.0775,  0.3945,\n",
       "                       -0.2784,  0.0990,  0.0178,  0.1539,  0.1839,  0.1915,  0.2322, -0.3248,\n",
       "                       -0.1112, -0.0649,  0.1763, -0.2260]])),\n",
       "             ('layers.4.bias', tensor([ 0.1769, -0.1287]))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in ./model.pth\n",
    "torch.save(model.state_dict(),\"model.pth\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_=NeuralNetwork(2,2)\n",
    "model_.load_state_dict(torch.load(\"model.pth\",weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()\n",
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1= torch.tensor([1,2,3])\n",
    "tensor_2= torch.tensor([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1 + tenso_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1.device , tensor_2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1_gpu=tensor_1.to(\"mps\")\n",
    "tensor_2_gpu=tensor_2.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 6], device='mps:0')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1_gpu + tensor_1_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Batch 0/2 | Train Loss 0.75 \n",
      "Epoch 1/3 | Batch 1/2 | Train Loss 0.24 \n",
      "Epoch 2/3 | Batch 0/2 | Train Loss 0.05 \n",
      "Epoch 2/3 | Batch 1/2 | Train Loss 0.05 \n",
      "Epoch 3/3 | Batch 0/2 | Train Loss 0.01 \n",
      "Epoch 3/3 | Batch 1/2 | Train Loss 0.01 \n"
     ]
    }
   ],
   "source": [
    "model= NeuralNetwork(2,2)\n",
    "model= model.to(\"mps\")\n",
    "\n",
    "optimizer= torch.optim.SGD(model.parameters(),lr=0.5)\n",
    "\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        x,y= x.to(\"mps\"), y.to(\"mps\")\n",
    "        logits= model(x)\n",
    "        loss= F.cross_entropy(logits,y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Batch {i}/{len(train_loader)} | Train Loss {loss:.2f} \")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3919,  0.6465],\n",
       "        [ 0.2414, -0.3386],\n",
       "        [ 0.7003, -0.0879],\n",
       "        [ 0.2894, -0.6232],\n",
       "        [-0.1410,  0.5893],\n",
       "        [ 0.3068,  0.3856],\n",
       "        [-0.4816, -0.0227],\n",
       "        [ 0.6579, -0.1860],\n",
       "        [ 0.0480,  0.0899],\n",
       "        [ 0.5136,  0.6083],\n",
       "        [ 0.0649,  0.4637],\n",
       "        [-0.2341, -0.5823],\n",
       "        [ 0.4045, -0.3357],\n",
       "        [ 0.5693, -0.0379],\n",
       "        [-0.6205, -0.1499],\n",
       "        [-0.5333, -0.4889],\n",
       "        [-0.2865,  0.1733],\n",
       "        [-0.2331,  0.5681],\n",
       "        [ 0.0653,  0.6471],\n",
       "        [ 0.5679, -0.6270],\n",
       "        [ 0.2700, -0.3539],\n",
       "        [ 0.6353, -0.6642],\n",
       "        [-0.2211,  0.4684],\n",
       "        [-0.4319, -0.4663],\n",
       "        [ 0.0288,  0.6920],\n",
       "        [ 0.6842, -0.3701],\n",
       "        [ 0.6187,  0.0133],\n",
       "        [ 0.6674, -0.5207],\n",
       "        [-0.4751, -0.0205],\n",
       "        [-0.5889,  0.0441]], device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
